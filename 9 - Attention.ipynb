{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMT con attention\n",
    "\n",
    "- Vimos una forma de implementar many to one, pero hay otra:\n",
    "\n",
    "<img src=\"many2one.png\">\n",
    "\n",
    "- La LSTM no es capaz de guardar un estado para secuencias muy largas, si bien tiene mas memoria que la SimpleRNN.\n",
    "_ La segunda topología mira todos los estados intermedios y elige el feature mas importante (como el max pooling de la CNN).\n",
    "- Otra opción es usar una softmax (coamo alternativa a hard max).\n",
    "\n",
    "Esta es la idea prinipal de attention: si bien uno tiene acceso a todos los features, en vez de darle la misma importancia a todos, se los pesa con algún criterio (próximo a definir).\n",
    "Ese criterio está definido por una mini-red neuronal dentro de la red neuronal total. (Como la LSTM o la GRU).\n",
    "\n",
    "Para el traductor, dejaremos de usar la primera estructura y pasaremos a la segunda:\n",
    "\n",
    "<img src=\"NMT-attention.png\">\n",
    "\n",
    "El diagrama completo con attention queda:\n",
    "\n",
    "<img src=\"NMT-conetxt.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante distinguir la variable tiempo a la entrada de la variable tiempo a la salida, por eso a la variable tiempo a la entrada (que va de 1 hasta Tx) la llamaremos t'. A la variable tiempo de salida (que va de 1 hasta Ty la llamaremos t).\n",
    "\n",
    "A cada una de las celdas LSTM del decoder le llega un vector de contexto, que es un promedio ponderado de cada uno de los estados de la LSTM. A los factores de ponderamiento los llamaremos $\\alpha(t')$.  \n",
    "Los $\\alpha$ definirán cuanta atención se pondrá a cada estado del encoder.\n",
    "\n",
    "Los $\\alpha$ son obtenidos con la mini-nn mencionada anteriormente. Esa mini-nn estima estos parámetros en función del estado en t-1 del decoder (ya que da información de dónde estoy en la oración de salida) y de los estados del enconder (que contienen la información de la oración que estoy traduciendo).\n",
    "\n",
    "Discusión:\n",
    "\n",
    "How are you today? ¿Cómo estás hoy?\n",
    "\n",
    "Como se calcula attention:\n",
    "\n",
    "$ z_1(t,t')=concat[ s(t-1), h(t') ] $ -> $dim= \\#decoStates + 2 \\#encoStates$  \n",
    "\n",
    "$ z_2(t) = [z_1(t,1)...,...z1(t,T_x) ] $ -> $dim= (T_x, \\#decoStates + 2 \\#encoStates)$   \n",
    "\n",
    "$ z_3(t) = f(W_1*z_2(t)+b_1) $ -> $dim=(T_x,Attention_dim)$, $f$ podría ser una tanh o una función lineal.  \n",
    "\n",
    "$ alphas(t,t')=softmax(W_2*z3+b_2)$ $dim=(T_x,1)$ -> **Pero esto tiene un problema, ya que la softmax de Keras realiza la operación en el eje incorrecto!. Todas las salidas valdrían 1!.**  \n",
    "\n",
    "$ alphas(t,t')=softmaxOverTime(W_2*z3+b_2)$ -> Se implementa la softmax_over_time de forma tal que aplique la softmax en el axis=1 y no en el axis=2.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding, \\\n",
    "  Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 256\n",
    "LATENT_DIM_DECODER = 256 # idea: make it different to ensure things all fit together properly!\n",
    "NUM_SAMPLES = 10000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "START_SAMPLE=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_over_time(x):\n",
    "    #assert(K.ndim(x) > 2)\n",
    "    #e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
    "    #s = K.sum(e, axis=1, keepdims=True)\n",
    "    #return e / s\n",
    "    return K.softmax(x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where we will store the data\n",
    "input_texts = [] # sentence in original language\n",
    "target_texts = [] # sentence in target language\n",
    "target_texts_inputs = [] # sentence in target language offset by 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 10000\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "k=0\n",
    "for line in open('fra-eng/fra.txt'):\n",
    "    # only keep a limited number of samples\n",
    "    k +=1\n",
    "    if k>START_SAMPLE:\n",
    "        t += 1\n",
    "        if t > NUM_SAMPLES:\n",
    "            break\n",
    "\n",
    "        # input and target are separated by tab\n",
    "        if '\\t' not in line:\n",
    "            continue\n",
    "\n",
    "        # split up the input and translation\n",
    "        input_text, translation = line.rstrip().split('\\t')\n",
    "\n",
    "        # make the target input and output\n",
    "        # recall we'll be using teacher forcing\n",
    "        target_text = translation + ' <eos>'\n",
    "        target_text_input = '<sos> ' + translation\n",
    "        input_texts.append(input_text)\n",
    "        target_texts.append(target_text)\n",
    "        target_texts_inputs.append(target_text_input)\n",
    "    if t > NUM_SAMPLES:\n",
    "            break\n",
    "print(\"num samples:\", len(input_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<sos> Je pense que vous êtes celui qui l'a cassée.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_text_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My best friend stole my boyfriend.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ma meilleure amie m'a piqué mon petit copain. <eos>\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<sos> Ma meilleure amie m'a piqué mon petit copain.\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts_inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the inputs\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La oración My uncle lives next to the school. se codifica como [20, 688, 381, 172, 2, 4, 124]\n"
     ]
    }
   ],
   "source": [
    "idx=50\n",
    "print(\"La oración {} se codifica como {}\".format(input_texts[idx],input_sequences[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El vocabulario origen tiene 4358 palabras.\n"
     ]
    }
   ],
   "source": [
    "# get the word to index mapping for input language\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('El vocabulario origen tiene %s palabras.' % len(word2idx_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx_inputs[\"uncle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# determine maximum length input sequence\n",
    "max_len_input = max(len(s) for s in input_sequences)\n",
    "print(max_len_input)\n",
    "# recordar que ahora son palabras, no letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the outputs\n",
    "# don't filter out special characters\n",
    "# otherwise <sos> and <eos> won't appear\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el decoder, la oración en francés Mon père avait déjà été en Grèce. <eos> se codifica como [37, 202, 176, 177, 53, 23, 4487, 1]\n",
      "En el decoder, la oración en francés <sos> Mon père avait déjà été en Grèce. se codifica como [2, 37, 202, 176, 177, 53, 23, 4487]\n"
     ]
    }
   ],
   "source": [
    "idx=15\n",
    "print(\"En el decoder, la oración en francés {} se codifica como {}\".format(target_texts[idx],target_sequences[idx]))\n",
    "print(\"En el decoder, la oración en francés {} se codifica como {}\".format(target_texts_inputs[idx],target_sequences_inputs[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El vocabulario destino tiene 9268 palabras.\n"
     ]
    }
   ],
   "source": [
    "# get the word to index mapping for output language\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('El vocabulario destino tiene %s palabras.' % len(word2idx_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store number of output words for later\n",
    "# remember to add 1 since indexing starts at 1\n",
    "num_words_output = len(word2idx_outputs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad máxima de palabras de la secuencia para el decoder es 17.\n"
     ]
    }
   ],
   "source": [
    "# determine maximum length output sequence\n",
    "max_len_target = max(len(s) for s in target_sequences)\n",
    "print(\"La cantidad máxima de palabras de la secuencia para el decoder es {}.\".format(max_len_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_data.shape: (10000, 11)\n",
      "encoder_data[0]: [  0   0   0   0  20 688 381 172   2   4 124]\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_data.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_data[0]:\", encoder_inputs[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_data[0]: [   2   51  920 1019   97 4481   37  264 4482    0    0    0    0    0\n",
      "    0    0    0]\n",
      "decoder_data.shape: (10000, 17)\n"
     ]
    }
   ],
   "source": [
    "# Recordar que el 2 es <sos>\n",
    "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
    "print(\"decoder_data[0]:\", decoder_inputs[0])\n",
    "print(\"decoder_data.shape:\", decoder_inputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  51,  920, 1019,   97, 4481,   37,  264, 4482,    1,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recordar que el 1 es <eos>\n",
    "decoder_targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# store all the pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(os.path.join('glove/glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i < MAX_NUM_WORDS:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=max_len_input,\n",
    "  #trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec[\"the\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets, since we cannot use sparse\n",
    "# categorical cross entropy when we have sequences\n",
    "decoder_targets_one_hot = np.zeros(\n",
    "  (\n",
    "    len(input_texts),\n",
    "    max_len_target,\n",
    "    num_words_output\n",
    "  ),\n",
    "  dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the values\n",
    "for i, d in enumerate(decoder_targets):\n",
    "    for t, word in enumerate(d):\n",
    "        decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### build the model #####\n",
    "\n",
    "# Set up the encoder - simple!\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = Bidirectional(LSTM(LATENT_DIM, return_sequences=True, dropout=0.5))\n",
    "encoder_outputs = encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder - not so simple\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "\n",
    "# this word embedding will not use pre-trained vectors\n",
    "# although you could\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Attention #########\n",
    "# Attention layers need to be global because\n",
    "# they will be repeated Ty times at the decoder\n",
    "attn_repeat_layer = RepeatVector(max_len_input)\n",
    "attn_concat_layer = Concatenate(axis=-1)\n",
    "attn_dense1 = Dense(10, activation='tanh')\n",
    "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
    "attn_dot = Dot(axes=1) # to perform the weighted sum of alpha[t] * h[t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de attention para una celda de salida.\n",
    "\n",
    "Se implementará una función que a partir de una lista de las salidas del encoder y el estado en el instante de tiempo anterior del decoder, devuelve el vector de contexto y los alphas que se usaron para poderar a los h para calcular el vector de contexto.\n",
    "\n",
    "A continuación se muestra el diagrama implementado por la función:\n",
    "\n",
    "<img src=\"attention.png\">\n",
    "\n",
    "1) La función recibe una lista con las salidas (h) del encoder y el estado anterior del decoder s(t-1).  \n",
    "2) Se repite s(t-1) Tx veces, de manera tal que se pueda concatenar a cada h con una repetición de s(t-1).  \n",
    "3) Se realiza la concatenación de la lista de h y s(t-1).  \n",
    "4) Se lo pasa por una capa densa de Att_dim neuronas. Es muy importante recordar que cuando uno procesa un vector de dimensiones (Tx, N=latent_encoder_dim+2\\*latent_decoder_dim) con una capa densa, la capa densa multiplica por la matriz de pesos cada uno de los TX vectores de tamaño N y aplica la función de activación independientemente a cada una de las salidas de estas multiplicaciones, según se muestra en (b).  \n",
    "5) A cada uno de los Tx vectores de tamaño Att_dim que salen de la capa anterior, se los multiplica por el mismo vector de pesos de tamaño Att_dim. Esto se logra fácilmente aplicando una capa densa con una sola neurona.  \n",
    "6) A cada uno de los valores obtenidos en el punto anterior, se los procesa con una softmax para obtener los alpha. Tipicamente en una red neuronal tendría Tx vectores de salida y cada uno de estos vectores se procesarían con una softmax. Si hiciera esto en este caso, con vectores de salida de tamaño 1, tendria Tx salidas cuyo valor es 1, ya que una softmax aplicada a un solo valor, vale 1. Lo que se necesita es una softmax que tenga en cuenta a cada una de las Tx salidas en conjunto, y eso se logra aplicando la softmax en el axis 1 en vez del axis 2 (el cual sería el default en este caso).  \n",
    "\n",
    "En el diagrama se muestran las dos posibles configuraciones de softmax para mayor claridad.  \n",
    "\n",
    "En (c) se muestra una red neuronal de una sola salida, con softmax.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(h, st_1):\n",
    "    # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
    "    # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
    "\n",
    "    #Paso 1: se repite s(t-1) Tx veces para poder concatenarlo con los h\n",
    "    st_1 = attn_repeat_layer(st_1)\n",
    "\n",
    "    # Se concatena la lista de s(t-1) repetido con la lista de los h\n",
    "    # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
    "    x = attn_concat_layer([h, st_1])\n",
    "\n",
    "    # Se pasa la lista de vectores concatenados por la primera capa densa\n",
    "    x = attn_dense1(x)\n",
    "    \n",
    "    # Neural net second layer with special softmax over time\n",
    "    alphas = attn_dense2(x)\n",
    "    print(alphas)\n",
    "    # \"Dot\" the alphas and the h's\n",
    "    # Remember a.dot(b) = sum over a[t] * b[t]\n",
    "    context = attn_dot([alphas, h])\n",
    "    return [context,alphas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the rest of the decoder (after attention)\n",
    "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "\n",
    "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
    "context_last_word_concat_layer = Concatenate(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s, c will be re-assigned in each iteration of the loop\n",
    "s = initial_s\n",
    "c = initial_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_9/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_1/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_2/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_3/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_4/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_5/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_6/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_7/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_8/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_9/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_10/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_11/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_12/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_13/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_14/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_15/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n",
      "Tensor(\"dense_9_16/transpose_2:0\", shape=(?, 11, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# collect outputs in a list at first\n",
    "outputs = []\n",
    "for t in range(max_len_target): # Ty times\n",
    "    # get the context using attention\n",
    "    context,alphas = one_step_attention(encoder_outputs, s)\n",
    "\n",
    "    # we need a different layer for each time step\n",
    "    selector = Lambda(lambda x: x[:, t:t+1])\n",
    "    xt = selector(decoder_inputs_x)\n",
    "\n",
    "    # combine \n",
    "    decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "\n",
    "    # pass the combined [context, last word] into the LSTM\n",
    "    # along with [s, c]\n",
    "    # get the new [s, c] and output\n",
    "    o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
    "\n",
    "    # final dense layer to get next word prediction\n",
    "    decoder_outputs = decoder_dense(o)\n",
    "    outputs.append(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'outputs' is now a list of length Ty\n",
    "# each element is of shape (batch size, output vocab size)\n",
    "# therefore if we simply stack all the outputs into 1 tensor\n",
    "# it would be of shape T x N x D\n",
    "# we would like it to be of shape N x T x D\n",
    "\n",
    "def stack_and_transpose(x):\n",
    "  # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n",
    "  x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
    "  x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now batch_size x T x output_vocab_size\n",
    "  return x\n",
    "\n",
    "# make it a layer\n",
    "stacker = Lambda(stack_and_transpose)\n",
    "outputs = stacker(outputs)\n",
    "\n",
    "# create the model\n",
    "model = Model(\n",
    "  inputs=[\n",
    "    encoder_inputs_placeholder,\n",
    "    decoder_inputs_placeholder,\n",
    "    initial_s, \n",
    "    initial_c,\n",
    "  ],\n",
    "  outputs=outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 13s 2ms/step - loss: 4.4239 - acc: 0.4873 - val_loss: 3.6753 - val_acc: 0.4844\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 5s 637us/step - loss: 3.3835 - acc: 0.5130 - val_loss: 3.5030 - val_acc: 0.4981\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 5s 638us/step - loss: 3.1061 - acc: 0.5383 - val_loss: 3.3120 - val_acc: 0.5107\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 2.9383 - acc: 0.5699 - val_loss: 3.1662 - val_acc: 0.5660\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 5s 636us/step - loss: 2.7942 - acc: 0.5894 - val_loss: 3.0767 - val_acc: 0.5737\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 5s 638us/step - loss: 2.6727 - acc: 0.5963 - val_loss: 3.0000 - val_acc: 0.5856\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 5s 638us/step - loss: 2.5680 - acc: 0.6034 - val_loss: 2.9402 - val_acc: 0.5912\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 5s 640us/step - loss: 2.4701 - acc: 0.6097 - val_loss: 2.8789 - val_acc: 0.5940\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 5s 638us/step - loss: 2.3758 - acc: 0.6164 - val_loss: 2.8142 - val_acc: 0.5986\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 2.2939 - acc: 0.6223 - val_loss: 2.8154 - val_acc: 0.5961\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 5s 639us/step - loss: 2.2198 - acc: 0.6283 - val_loss: 2.7524 - val_acc: 0.6045\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 2.1454 - acc: 0.6340 - val_loss: 2.7130 - val_acc: 0.6119\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 5s 639us/step - loss: 2.0727 - acc: 0.6406 - val_loss: 2.6766 - val_acc: 0.6137\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 5s 639us/step - loss: 2.0023 - acc: 0.6474 - val_loss: 2.6295 - val_acc: 0.6225\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 5s 639us/step - loss: 1.9364 - acc: 0.6537 - val_loss: 2.6159 - val_acc: 0.6245\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 5s 638us/step - loss: 1.8697 - acc: 0.6599 - val_loss: 2.5799 - val_acc: 0.6273\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 5s 639us/step - loss: 1.8060 - acc: 0.6664 - val_loss: 2.5762 - val_acc: 0.6256\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 5s 640us/step - loss: 1.7454 - acc: 0.6719 - val_loss: 2.5510 - val_acc: 0.6319\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 5s 639us/step - loss: 1.6844 - acc: 0.6782 - val_loss: 2.5295 - val_acc: 0.6339\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 5s 639us/step - loss: 1.6235 - acc: 0.6855 - val_loss: 2.5220 - val_acc: 0.6342\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 5s 639us/step - loss: 1.5684 - acc: 0.6918 - val_loss: 2.4970 - val_acc: 0.6378\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 1.5117 - acc: 0.6990 - val_loss: 2.5104 - val_acc: 0.6401\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 5s 640us/step - loss: 1.4583 - acc: 0.7056 - val_loss: 2.4879 - val_acc: 0.6402\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 1.4055 - acc: 0.7122 - val_loss: 2.4650 - val_acc: 0.6464\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 5s 639us/step - loss: 1.3545 - acc: 0.7192 - val_loss: 2.4591 - val_acc: 0.6466\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 5s 639us/step - loss: 1.3069 - acc: 0.7262 - val_loss: 2.4616 - val_acc: 0.6470\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 1.2592 - acc: 0.7342 - val_loss: 2.4575 - val_acc: 0.6499\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 1.2134 - acc: 0.7410 - val_loss: 2.4459 - val_acc: 0.6521\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 5s 640us/step - loss: 1.1688 - acc: 0.7486 - val_loss: 2.4464 - val_acc: 0.6518\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 1.1244 - acc: 0.7566 - val_loss: 2.4370 - val_acc: 0.6529\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 5s 640us/step - loss: 1.0848 - acc: 0.7637 - val_loss: 2.4363 - val_acc: 0.6556\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 5s 639us/step - loss: 1.0436 - acc: 0.7713 - val_loss: 2.4171 - val_acc: 0.6579\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 5s 640us/step - loss: 1.0067 - acc: 0.7798 - val_loss: 2.4145 - val_acc: 0.6568\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 0.9683 - acc: 0.7868 - val_loss: 2.4258 - val_acc: 0.6588\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.9319 - acc: 0.7943 - val_loss: 2.4272 - val_acc: 0.6587\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.8961 - acc: 0.8025 - val_loss: 2.4245 - val_acc: 0.6597\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 0.8619 - acc: 0.8100 - val_loss: 2.4108 - val_acc: 0.6619\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 5s 640us/step - loss: 0.8306 - acc: 0.8159 - val_loss: 2.4065 - val_acc: 0.6640\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 5s 640us/step - loss: 0.8000 - acc: 0.8231 - val_loss: 2.4087 - val_acc: 0.6636\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 5s 640us/step - loss: 0.7678 - acc: 0.8297 - val_loss: 2.4161 - val_acc: 0.6640\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.7391 - acc: 0.8348 - val_loss: 2.4215 - val_acc: 0.6651\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.7111 - acc: 0.8418 - val_loss: 2.4230 - val_acc: 0.6656\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 5s 646us/step - loss: 0.6858 - acc: 0.8467 - val_loss: 2.4204 - val_acc: 0.6666\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.6585 - acc: 0.8529 - val_loss: 2.4149 - val_acc: 0.6666\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 0.6355 - acc: 0.8582 - val_loss: 2.4178 - val_acc: 0.6683\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 0.6097 - acc: 0.8633 - val_loss: 2.4315 - val_acc: 0.6659\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 5s 644us/step - loss: 0.5884 - acc: 0.8679 - val_loss: 2.4202 - val_acc: 0.6701\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 5s 645us/step - loss: 0.5647 - acc: 0.8732 - val_loss: 2.4122 - val_acc: 0.6673\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.5435 - acc: 0.8773 - val_loss: 2.4187 - val_acc: 0.6687\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 0.5232 - acc: 0.8826 - val_loss: 2.4224 - val_acc: 0.6700\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 5s 640us/step - loss: 0.5032 - acc: 0.8865 - val_loss: 2.4337 - val_acc: 0.6713\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.4844 - acc: 0.8906 - val_loss: 2.4424 - val_acc: 0.6706\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.4648 - acc: 0.8948 - val_loss: 2.4419 - val_acc: 0.6713\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.4487 - acc: 0.8983 - val_loss: 2.4537 - val_acc: 0.6719\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.4303 - acc: 0.9027 - val_loss: 2.4524 - val_acc: 0.6720\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.4143 - acc: 0.9064 - val_loss: 2.4566 - val_acc: 0.6711\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 0.3976 - acc: 0.9091 - val_loss: 2.4453 - val_acc: 0.6723\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.3823 - acc: 0.9134 - val_loss: 2.4818 - val_acc: 0.6709\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.3672 - acc: 0.9168 - val_loss: 2.4748 - val_acc: 0.6713\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 5s 644us/step - loss: 0.3530 - acc: 0.9200 - val_loss: 2.4730 - val_acc: 0.6729\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.3380 - acc: 0.9233 - val_loss: 2.4711 - val_acc: 0.6736\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.3273 - acc: 0.9249 - val_loss: 2.4843 - val_acc: 0.6729\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.3130 - acc: 0.9281 - val_loss: 2.4936 - val_acc: 0.6742\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 5s 646us/step - loss: 0.2994 - acc: 0.9319 - val_loss: 2.5036 - val_acc: 0.6728\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.2897 - acc: 0.9334 - val_loss: 2.5007 - val_acc: 0.6741\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.2778 - acc: 0.9369 - val_loss: 2.5136 - val_acc: 0.6743\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 5s 640us/step - loss: 0.2665 - acc: 0.9382 - val_loss: 2.5212 - val_acc: 0.6743\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.2556 - acc: 0.9409 - val_loss: 2.5408 - val_acc: 0.6725\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.2463 - acc: 0.9432 - val_loss: 2.5230 - val_acc: 0.6739\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.2352 - acc: 0.9459 - val_loss: 2.5361 - val_acc: 0.6742\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.2263 - acc: 0.9477 - val_loss: 2.5451 - val_acc: 0.6731\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.2178 - acc: 0.9496 - val_loss: 2.5387 - val_acc: 0.6729\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.2083 - acc: 0.9511 - val_loss: 2.5548 - val_acc: 0.6738\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.2009 - acc: 0.9532 - val_loss: 2.5554 - val_acc: 0.6748\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.1918 - acc: 0.9551 - val_loss: 2.5682 - val_acc: 0.6735\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 5s 644us/step - loss: 0.1849 - acc: 0.9564 - val_loss: 2.5723 - val_acc: 0.6753\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 5s 644us/step - loss: 0.1787 - acc: 0.9577 - val_loss: 2.5758 - val_acc: 0.6760\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 5s 646us/step - loss: 0.1707 - acc: 0.9590 - val_loss: 2.5745 - val_acc: 0.6752\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 5s 645us/step - loss: 0.1650 - acc: 0.9605 - val_loss: 2.6063 - val_acc: 0.6740\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 0.1580 - acc: 0.9613 - val_loss: 2.6057 - val_acc: 0.6758\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 5s 644us/step - loss: 0.1522 - acc: 0.9623 - val_loss: 2.6108 - val_acc: 0.6752\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.1467 - acc: 0.9634 - val_loss: 2.6011 - val_acc: 0.6753\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.1416 - acc: 0.9642 - val_loss: 2.6233 - val_acc: 0.6750\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 5s 644us/step - loss: 0.1362 - acc: 0.9654 - val_loss: 2.6285 - val_acc: 0.6754\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 5s 641us/step - loss: 0.1315 - acc: 0.9659 - val_loss: 2.6464 - val_acc: 0.6738\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.1271 - acc: 0.9672 - val_loss: 2.6391 - val_acc: 0.6741\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 5s 644us/step - loss: 0.1220 - acc: 0.9677 - val_loss: 2.6603 - val_acc: 0.6745\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 5s 646us/step - loss: 0.1183 - acc: 0.9684 - val_loss: 2.6668 - val_acc: 0.6743\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 5s 645us/step - loss: 0.1149 - acc: 0.9686 - val_loss: 2.6537 - val_acc: 0.6742\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.1116 - acc: 0.9691 - val_loss: 2.6727 - val_acc: 0.6737\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 5s 648us/step - loss: 0.1068 - acc: 0.9699 - val_loss: 2.6752 - val_acc: 0.6742\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 5s 644us/step - loss: 0.1042 - acc: 0.9700 - val_loss: 2.6848 - val_acc: 0.6745\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 5s 642us/step - loss: 0.1009 - acc: 0.9706 - val_loss: 2.6983 - val_acc: 0.6742\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 5s 645us/step - loss: 0.0967 - acc: 0.9716 - val_loss: 2.7084 - val_acc: 0.6755\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 5s 649us/step - loss: 0.0949 - acc: 0.9718 - val_loss: 2.7096 - val_acc: 0.6748\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 5s 644us/step - loss: 0.0923 - acc: 0.9718 - val_loss: 2.7245 - val_acc: 0.6743\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 5s 643us/step - loss: 0.0900 - acc: 0.9722 - val_loss: 2.7129 - val_acc: 0.6743\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 5s 644us/step - loss: 0.0875 - acc: 0.9727 - val_loss: 2.7233 - val_acc: 0.6745\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 5s 648us/step - loss: 0.0849 - acc: 0.9733 - val_loss: 2.7314 - val_acc: 0.6749\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 5s 644us/step - loss: 0.0828 - acc: 0.9736 - val_loss: 2.7401 - val_acc: 0.6733\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "z = np.zeros((NUM_SAMPLES, LATENT_DIM_DECODER)) # initial [s, c]\n",
    "r = model.fit(\n",
    "  [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=0.2\n",
    ")\n",
    "\n",
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['acc'], label='acc')\n",
    "plt.plot(r.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Make predictions #####\n",
    "# As with the poetry example, we need to create another model\n",
    "# that can take in the RNN state and previous word as input\n",
    "# and accept a T=1 sequence.\n",
    "\n",
    "# The encoder will be stand-alone\n",
    "# From this we will get our initial decoder hidden state\n",
    "# i.e. h(1), ..., h(Tx)\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
    "\n",
    "# next we define a T=1 decoder model\n",
    "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# no need to loop over attention steps this time because there is only one step\n",
    "context,alphas = one_step_attention(encoder_outputs_as_input, initial_s)\n",
    "\n",
    "# combine context with last word\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
    "\n",
    "# lstm and final dense\n",
    "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "decoder_outputs = decoder_dense(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "decoder_model = Model(\n",
    "  inputs=[\n",
    "    decoder_inputs_single,\n",
    "    encoder_outputs_as_input,\n",
    "    initial_s, \n",
    "    initial_c\n",
    "  ],\n",
    "  outputs=[decoder_outputs, s, c,alphas]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# map indexes back into real words\n",
    "# so we can view the results\n",
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  # Encode the input as state vectors.\n",
    "  enc_out = encoder_model.predict(input_seq)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1))\n",
    "  \n",
    "  # Populate the first character of target sequence with the start character.\n",
    "  # NOTE: tokenizer lower-cases all words\n",
    "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "  # if we get this we break\n",
    "  eos = word2idx_outputs['<eos>']\n",
    "\n",
    "\n",
    "  # [s, c] will be updated in each loop iteration\n",
    "  s = np.zeros((1, LATENT_DIM_DECODER))\n",
    "  c = np.zeros((1, LATENT_DIM_DECODER))\n",
    "\n",
    "\n",
    "  # Create the translation\n",
    "  output_sentence = []\n",
    "  attention=list()\n",
    "  for _ in range(max_len_target):\n",
    "    o, s, c,att = decoder_model.predict([target_seq, enc_out, s, c])\n",
    "\n",
    "    # Get next word\n",
    "    idx = np.argmax(o.flatten())\n",
    "\n",
    "    # End sentence of EOS\n",
    "    if eos == idx:\n",
    "      break\n",
    "\n",
    "    word = ''\n",
    "    if idx > 0:\n",
    "      attention.append(att)\n",
    "      word = idx2word_trans[idx]\n",
    "      output_sentence.append(word)\n",
    "    # Update the decoder input\n",
    "    # which is just the word just generated\n",
    "    target_seq[0, 0] = idx\n",
    "\n",
    "  return [' '.join(output_sentence),attention]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "[array([[[6.6730136e-04],\n",
      "        [3.6986501e-04],\n",
      "        [1.7219868e-04],\n",
      "        [9.4769857e-05],\n",
      "        [5.7208370e-05],\n",
      "        [3.9496274e-05],\n",
      "        [2.7851793e-05],\n",
      "        [1.1806949e-04],\n",
      "        [9.8977610e-04],\n",
      "        [1.0196244e-02],\n",
      "        [9.8726720e-01]]], dtype=float32), array([[[0.11568973],\n",
      "        [0.11481178],\n",
      "        [0.10910194],\n",
      "        [0.10217658],\n",
      "        [0.0934867 ],\n",
      "        [0.08753157],\n",
      "        [0.08102379],\n",
      "        [0.07526647],\n",
      "        [0.07308529],\n",
      "        [0.07198075],\n",
      "        [0.07584539]]], dtype=float32), array([[[0.10440028],\n",
      "        [0.10089081],\n",
      "        [0.09191166],\n",
      "        [0.08045451],\n",
      "        [0.07137188],\n",
      "        [0.06930311],\n",
      "        [0.06776162],\n",
      "        [0.0976239 ],\n",
      "        [0.10233378],\n",
      "        [0.10291257],\n",
      "        [0.11103582]]], dtype=float32), array([[[0.12688115],\n",
      "        [0.09279593],\n",
      "        [0.06283483],\n",
      "        [0.04574872],\n",
      "        [0.03630753],\n",
      "        [0.03348854],\n",
      "        [0.02882419],\n",
      "        [0.08309868],\n",
      "        [0.15745641],\n",
      "        [0.1641817 ],\n",
      "        [0.16838235]]], dtype=float32), array([[[0.08567971],\n",
      "        [0.04750949],\n",
      "        [0.03165241],\n",
      "        [0.02400335],\n",
      "        [0.01711826],\n",
      "        [0.01164192],\n",
      "        [0.00693571],\n",
      "        [0.01192932],\n",
      "        [0.11582364],\n",
      "        [0.20470303],\n",
      "        [0.44300312]]], dtype=float32)]\n",
      "Input sentence: It's important that you understand.\n",
      "Predicted translation: c'est important que vous compreniez.\n",
      "Actual translation: C'est important que vous compreniez. <eos>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/doctorado-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/doctorado-gpu/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/doctorado-gpu/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/doctorado-gpu/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-406d5bc27a56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Actual translation:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Continue? [Y/n]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mans\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/doctorado-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/doctorado-gpu/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  # Do some test translations\n",
    "  i = np.random.choice(len(input_texts))\n",
    "  input_seq = encoder_inputs[i:i+1]\n",
    "  translation,attention = decode_sequence(input_seq)\n",
    "  print('-')\n",
    "  print(attention)\n",
    "  print('Input sentence:', input_texts[i])\n",
    "  print('Predicted translation:', translation)\n",
    "  print('Actual translation:', target_texts[i])\n",
    "\n",
    "  ans = input(\"Continue? [Y/n]\")\n",
    "  if ans and ans.lower().startswith('n'):\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
