{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Bidireccional\n",
    "\n",
    "¿Por qué RNN bidireccional?\n",
    "\n",
    "Tareas de NLP -> Entidades: Nombres, fechas, lugares, etc.\n",
    "Para la detección de estas entidades, es mejor tener información de toda la secuencia de principio a fin, y no solamente hasta un t particular.\n",
    "\n",
    "\"**General** relativity is an exciting theory about the physics of space and time\".\n",
    "\n",
    "En esta oración \"General\" no es una entidad.\n",
    "\n",
    "\"**General** Zod is an enemy of Superman\"\n",
    "En esta oración \"General\" es una persona\n",
    "\n",
    "Esta decisión no se puede tomar si no miro toda la oración.\n",
    "Para este tipo de problemas se utilizan RNN Bidireccionales:\n",
    "\n",
    "<img src=\"bidir-rnn.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ¿Tiene sentido seguir viendo solamente el último estado?\n",
    "\n",
    "No, porque la backward RNN no procesó la secuencia. Tiene sentido definir:\n",
    "\n",
    "$$ out = [h^f_T, h^b_1] $$\n",
    "\n",
    "En el caso que uno quiera implementar many to one.\n",
    "\n",
    "Este es el comportamiento de bidirectional en Keras, si return_sequences=False\n",
    "\n",
    "Para implementarlo en Keras se hace muy fácilmente:\n",
    "\n",
    "LSTM(M) -> Bidirectional(LSTM(M))\n",
    "\n",
    "* ¿Cuándo no usar RNN bidireccionales?\n",
    "\n",
    "Cuando se hace predicción, ya que no tengo datos para $t > t_0$\n",
    "\n",
    "## ¿Cómo afecta return_states y return_sequences en una Bidirectional RNN?\n",
    "\n",
    "Implementemos un código de prueba para analizar el comportamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'bidirectional_1/concat:0' shape=(?, 6) dtype=float32>, <tf.Tensor 'bidirectional_1/while/Exit_3:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'bidirectional_1/while/Exit_4:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'bidirectional_1/while_1/Exit_3:0' shape=(?, 3) dtype=float32>, <tf.Tensor 'bidirectional_1/while_1/Exit_4:0' shape=(?, 3) dtype=float32>]\n",
      "o: [[-0.12775621  0.08350156  0.11283459  0.03120568  0.19451576 -0.16249882]]\n",
      "o.shape: (1, 6)\n",
      "h1: [[-0.12775621  0.08350156  0.11283459]]\n",
      "c1: [[-0.29039502  0.18522438  0.2624488 ]]\n",
      "h2: [[ 0.03120568  0.19451576 -0.16249882]]\n",
      "c2: [[ 0.05747079  0.3723364  -0.24965109]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Bidirectional\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "T = 8 #Cantidad de Timesteps\n",
    "D = 2 #Cantidad de entradas por timestep\n",
    "M = 3 #Cantidad de unidades en la capa oculta\n",
    "\n",
    "\n",
    "X = np.random.randn(1, T, D)\n",
    "\n",
    "\n",
    "input_ = Input(shape=(T, D))\n",
    "#rnn = Bidirectional(LSTM(M, return_state=True, return_sequences=True),merge_mode=\"concat\")\n",
    "rnn = Bidirectional(LSTM(M, return_state=True, return_sequences=False),merge_mode=\"concat\") \n",
    "# merge_mode, defalut=\"concat\"... también {'sum','ave','mul'}\n",
    "x = rnn(input_)\n",
    "print(x)\n",
    "model = Model(inputs=input_, outputs=x)\n",
    "o, h1, c1, h2, c2 = model.predict(X)\n",
    "print(\"o:\", o)\n",
    "print(\"o.shape:\", o.shape)\n",
    "print(\"h1:\", h1)\n",
    "print(\"c1:\", c1)\n",
    "print(\"h2:\", h2)\n",
    "print(\"c2:\", c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Función que devuelve datos formateados\n",
    "def get_data(data_path = 'fra-eng/fra.txt', num_samples = 10000):\n",
    "    # num_samples: Number of samples to train on.\n",
    "    # Vectorize the data.\n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    input_characters = set()\n",
    "    target_characters = set()\n",
    "    lines = open(data_path).read().split('\\n')\n",
    "    for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "        input_text, target_text = line.split('\\t')\n",
    "        # We use \"tab\" as the \"start sequence\" character\n",
    "        # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "        target_text = '\\t' + target_text + '\\n'\n",
    "        input_texts.append(input_text)\n",
    "        target_texts.append(target_text)\n",
    "        for char in input_text:\n",
    "            if char not in input_characters:\n",
    "                input_characters.add(char)\n",
    "        for char in target_text:\n",
    "            if char not in target_characters:\n",
    "                target_characters.add(char)\n",
    "    input_characters = sorted(list(input_characters))\n",
    "    target_characters = sorted(list(target_characters))\n",
    "    num_encoder_tokens = len(input_characters)\n",
    "    num_decoder_tokens = len(target_characters)\n",
    "    input_lenghts = [len(txt) for txt in input_texts]\n",
    "    output_lengths = [len(txt) for txt in target_texts]\n",
    "    max_encoder_seq_length = max(input_lenghts)\n",
    "    max_decoder_seq_length = max(output_lengths)\n",
    "    print('Traducción con secuencia mas larga (Notar el agregado de tab y enter):')\n",
    "    print(input_texts[np.argmax(output_lengths)])\n",
    "    print(target_texts[np.argmax(output_lengths)])\n",
    "\n",
    "    print('Number of samples:', len(input_texts))\n",
    "    print('Number of unique input tokens:', num_encoder_tokens)\n",
    "    print('Number of unique output tokens:', num_decoder_tokens)\n",
    "    print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "    print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "    input_token_index = dict(\n",
    "        [(char, i) for i, char in enumerate(input_characters)])\n",
    "    target_token_index = dict(\n",
    "        [(char, i) for i, char in enumerate(target_characters)])\n",
    "    encoder_input_data = np.zeros(\n",
    "        (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "        dtype='float32')\n",
    "    decoder_input_data = np.zeros(\n",
    "        (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "        dtype='float32')\n",
    "    decoder_target_data = np.zeros(\n",
    "        (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "        dtype='float32')\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        for t, char in enumerate(input_text):\n",
    "            encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "        for t, char in enumerate(target_text):\n",
    "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "            decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "            if t > 0:\n",
    "                # decoder_target_data will be ahead by one timestep\n",
    "                # and will not include the start character.\n",
    "                decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data, \\\n",
    "            input_token_index, target_token_index, \\\n",
    "            num_encoder_tokens, num_decoder_tokens, \\\n",
    "            max_encoder_seq_length, max_decoder_seq_length, \\\n",
    "            input_texts, target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traducción con secuencia mas larga (Notar el agregado de tab y enter):\n",
      "I figured I might be able to help.\n",
      "\tJe me suis imaginée que je pourrais être en mesure de donner un coup de main.\n",
      "\n",
      "Number of samples: 100000\n",
      "Number of unique input tokens: 80\n",
      "Number of unique output tokens: 110\n",
      "Max sequence length for inputs: 34\n",
      "Max sequence length for outputs: 79\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100000\n",
    "encoder_input_data, decoder_input_data, decoder_target_data, \\\n",
    "input_token_index, target_token_index, \\\n",
    "num_encoder_tokens, num_decoder_tokens,  \\\n",
    "max_encoder_seq_length, \\\n",
    "max_decoder_seq_length, \\\n",
    "input_texts, target_texts = get_data(num_samples = num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idioma Ingles:\n",
      "Entrada encoder: (100000, 34, 80)\n",
      "Idioma frances:\n",
      "Entrada decoder: (100000, 79, 110)\n",
      "Salida decoder: (100000, 79, 110)\n"
     ]
    }
   ],
   "source": [
    "print('Idioma Ingles:')\n",
    "print('Entrada encoder:', encoder_input_data.shape)\n",
    "print('Idioma frances:')\n",
    "print('Entrada decoder:', decoder_input_data.shape)\n",
    "print('Salida decoder:', decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_Inputs (InputLayer)     (None, None, 80)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 256), (None, 214016      Encoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Dencoder_Inputs (InputLayer)    (None, None, 110)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256)          0           bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM (LSTM)             [(None, None, 256),  375808      Dencoder_Inputs[0][0]            \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Model_Output (Dense)            (None, None, 110)    28270       Decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 618,094\n",
      "Trainable params: 618,094\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, TimeDistributed, concatenate, Bidirectional\n",
    "# Estamos utilizando la Functional API\n",
    "\n",
    "# Esto es donde guardará el contexto\n",
    "latent_dim = 128  # Latent dimensionality of the encoding space.\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), name=\"Encoder_Inputs\") #num_encoder_tokens es la cantidad de features a la entrada\n",
    "encoder = Bidirectional(LSTM(latent_dim, return_state=True, name=\"Encoder_LSTM\"))\n",
    "encoder_outputs = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [concatenate([encoder_outputs[1], encoder_outputs[3]]),concatenate([encoder_outputs[2], encoder_outputs[4]])]\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name=\"Dencoder_Inputs\") #num_decoder_tokens es la cantidad de features a la entrada del decoder\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(2*latent_dim, return_sequences=True, return_state=True, name=\"Decoder_LSTM\")\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Model_Output')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/100\n",
      "80000/80000 [==============================] - 34s 423us/step - loss: 0.9372 - val_loss: 1.0184\n",
      "Epoch 2/100\n",
      "80000/80000 [==============================] - 33s 411us/step - loss: 0.6661 - val_loss: 0.8818\n",
      "Epoch 3/100\n",
      "80000/80000 [==============================] - 33s 410us/step - loss: 0.5880 - val_loss: 0.8081\n",
      "Epoch 4/100\n",
      "80000/80000 [==============================] - 33s 410us/step - loss: 0.5412 - val_loss: 0.7568\n",
      "Epoch 5/100\n",
      "80000/80000 [==============================] - 33s 411us/step - loss: 0.5064 - val_loss: 0.7174\n",
      "Epoch 6/100\n",
      "80000/80000 [==============================] - 33s 411us/step - loss: 0.4799 - val_loss: 0.6857\n",
      "Epoch 7/100\n",
      "80000/80000 [==============================] - 33s 412us/step - loss: 0.4576 - val_loss: 0.6584\n",
      "Epoch 8/100\n",
      "80000/80000 [==============================] - 33s 411us/step - loss: 0.4387 - val_loss: 0.6357\n",
      "Epoch 9/100\n",
      "80000/80000 [==============================] - 33s 411us/step - loss: 0.4224 - val_loss: 0.6164\n",
      "Epoch 10/100\n",
      "80000/80000 [==============================] - 33s 411us/step - loss: 0.4081 - val_loss: 0.6002\n",
      "Epoch 11/100\n",
      "80000/80000 [==============================] - 33s 409us/step - loss: 0.3960 - val_loss: 0.5844\n",
      "Epoch 12/100\n",
      "80000/80000 [==============================] - 33s 408us/step - loss: 0.3847 - val_loss: 0.5725\n",
      "Epoch 13/100\n",
      "80000/80000 [==============================] - 33s 408us/step - loss: 0.3748 - val_loss: 0.5600\n",
      "Epoch 14/100\n",
      "80000/80000 [==============================] - 33s 408us/step - loss: 0.3658 - val_loss: 0.5509\n",
      "Epoch 15/100\n",
      "80000/80000 [==============================] - 33s 408us/step - loss: 0.3578 - val_loss: 0.5432\n",
      "Epoch 16/100\n",
      "80000/80000 [==============================] - 33s 407us/step - loss: 0.3499 - val_loss: 0.5336\n",
      "Epoch 17/100\n",
      "80000/80000 [==============================] - 33s 408us/step - loss: 0.3428 - val_loss: 0.5253\n",
      "Epoch 18/100\n",
      "80000/80000 [==============================] - 33s 407us/step - loss: 0.3361 - val_loss: 0.5192\n",
      "Epoch 19/100\n",
      "80000/80000 [==============================] - 33s 407us/step - loss: 0.3301 - val_loss: 0.5112\n",
      "Epoch 20/100\n",
      "80000/80000 [==============================] - 32s 406us/step - loss: 0.3241 - val_loss: 0.5038\n",
      "Epoch 21/100\n",
      "80000/80000 [==============================] - 32s 405us/step - loss: 0.3187 - val_loss: 0.5023\n",
      "Epoch 22/100\n",
      "80000/80000 [==============================] - 32s 405us/step - loss: 0.3136 - val_loss: 0.4962\n",
      "Epoch 23/100\n",
      "80000/80000 [==============================] - 32s 405us/step - loss: 0.3088 - val_loss: 0.4906\n",
      "Epoch 24/100\n",
      "80000/80000 [==============================] - 32s 405us/step - loss: 0.3040 - val_loss: 0.4846\n",
      "Epoch 25/100\n",
      "80000/80000 [==============================] - 32s 405us/step - loss: 0.2997 - val_loss: 0.4816\n",
      "Epoch 26/100\n",
      "80000/80000 [==============================] - 32s 406us/step - loss: 0.2957 - val_loss: 0.4782\n",
      "Epoch 27/100\n",
      "80000/80000 [==============================] - 32s 406us/step - loss: 0.2915 - val_loss: 0.4744\n",
      "Epoch 28/100\n",
      "80000/80000 [==============================] - 33s 407us/step - loss: 0.2878 - val_loss: 0.4713\n",
      "Epoch 29/100\n",
      "80000/80000 [==============================] - 33s 406us/step - loss: 0.2842 - val_loss: 0.4687\n",
      "Epoch 30/100\n",
      "80000/80000 [==============================] - 33s 406us/step - loss: 0.2808 - val_loss: 0.4654\n",
      "Epoch 31/100\n",
      "80000/80000 [==============================] - 33s 406us/step - loss: 0.2776 - val_loss: 0.4637\n",
      "Epoch 32/100\n",
      "80000/80000 [==============================] - 33s 406us/step - loss: 0.2743 - val_loss: 0.4608\n",
      "Epoch 33/100\n",
      "74752/80000 [===========================>..] - ETA: 1s - loss: 0.2715"
     ]
    }
   ],
   "source": [
    "# Run training\n",
    "batch_size = 256  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = Input(shape=(2*latent_dim,), name=\"State_input_h\")\n",
    "decoder_state_input_c = Input(shape=(2*latent_dim,), name=\"State_input_c\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Va !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Cours !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Cours !\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Chantez-vous !\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Au feu !\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: À l'aide !\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Saute.\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Je comprends.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: J'essaye.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je l'ai emporté !\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je l'ai emporté !\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: Oh non !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attaque !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attaque !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Santé !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Santé !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Santé !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Santé !\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Lève-toi.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Compris !\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Compris !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Pigé ?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Pigé ?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Pigé ?\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Monte.\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Monte.\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Serre-moi dans tes bras !\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Serre-moi dans tes bras !\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je suis tombé.\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je suis tombé.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: Je sais.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis parti.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis parti.\n",
      "\n",
      "-\n",
      "Input sentence: I lost.\n",
      "Decoded sentence: J'ai perdu.\n",
      "\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence: J'ai 19 ans.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je vais bien.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je vais bien.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Écoutez !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possid !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possid !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possid !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possid !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possid !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possid !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possid !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possid !\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Vraiment ?\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Vraiment ?\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Vraiment ?\n",
      "\n",
      "-\n",
      "Input sentence: Thanks.\n",
      "Decoded sentence: Merci !\n",
      "\n",
      "-\n",
      "Input sentence: We try.\n",
      "Decoded sentence: On essaye.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous l'emportâmes.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous l'emportâmes.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous l'emportâmes.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous l'emportâmes.\n",
      "\n",
      "-\n",
      "Input sentence: Ask Tom.\n",
      "Decoded sentence: Demande à Tom.\n",
      "\n",
      "-\n",
      "Input sentence: Awesome!\n",
      "Decoded sentence: Fantastique !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Soyez calme !\n",
      "\n",
      "-\n",
      "Input sentence: Be cool.\n",
      "Decoded sentence: Sois détendu !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be kind.\n",
      "Decoded sentence: Sois gentil.\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentilles !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentilles !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentilles !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentilles !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentilles !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentilles !\n",
      "\n",
      "-\n",
      "Input sentence: Beat it.\n",
      "Decoded sentence: Dégage !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Appelle-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Appelle-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Appelez-nous !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Appelez-nous !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entrez !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entrez !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entrez !\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Entrez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on!\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Venez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Venez !\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Venez !\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Laissez tomber !\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Laissez tomber !\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Laissez tomber !\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Laissez tomber !\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: Sortez !\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: Sortez !\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: Sortez !\n",
      "\n",
      "-\n",
      "Input sentence: Get out.\n",
      "Decoded sentence: Sors.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training test)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traducción con secuencia mas larga (Notar el agregado de tab y enter):\n",
      "I got carded.\n",
      "\tOn m'a demandé ma carte d'identité pour vérifier mon âge.\n",
      "\n",
      "Number of samples: 20000\n",
      "Number of unique input tokens: 74\n",
      "Number of unique output tokens: 102\n",
      "Max sequence length for inputs: 19\n",
      "Max sequence length for outputs: 59\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3c7142c370d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_texts2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_texts2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "input_texts2, target_texts2 = get_data(num_samples = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Tom is playing.\n",
      "Decoded sentence: Tom astentend.\n",
      "\n",
      "-\n",
      "Input sentence: Tom is special.\n",
      "Decoded sentence: Tom est hépoil.\n",
      "\n",
      "-\n",
      "Input sentence: Tom is starved.\n",
      "Decoded sentence: Tom est arousé.\n",
      "\n",
      "-\n",
      "Input sentence: Tom is starved.\n",
      "Decoded sentence: Tom est arousé.\n",
      "\n",
      "-\n",
      "Input sentence: Tom is staying.\n",
      "Decoded sentence: Tom est en train de parter.\n",
      "\n",
      "-\n",
      "Input sentence: Tom is talking.\n",
      "Decoded sentence: Tom est en train de travailler.\n",
      "\n",
      "-\n",
      "Input sentence: Tom is working.\n",
      "Decoded sentence: Tom est en train de travailler.\n",
      "\n",
      "-\n",
      "Input sentence: Tom isn't dumb.\n",
      "Decoded sentence: Tom est marrail mointéaux.\n",
      "\n",
      "-\n",
      "Input sentence: Tom isn't here.\n",
      "Decoded sentence: Tom ve la faire.\n",
      "\n",
      "-\n",
      "Input sentence: Tom isn't rich.\n",
      "Decoded sentence: Tom ne prépare de sempri.\n",
      "\n",
      "-\n",
      "Input sentence: Tom isn't rude.\n",
      "Decoded sentence: Tom ne fait pas marchen.\n",
      "\n",
      "-\n",
      "Input sentence: Tom knows that.\n",
      "Decoded sentence: Toi vent est acruvée.\n",
      "\n",
      "-\n",
      "Input sentence: Tom knows that.\n",
      "Decoded sentence: Toi vent est acruvée.\n",
      "\n",
      "-\n",
      "Input sentence: Tom liked that.\n",
      "Decoded sentence: Toma le rémarsée.\n",
      "\n",
      "-\n",
      "Input sentence: Tom likes snow.\n",
      "Decoded sentence: Toi vons plais.\n",
      "\n",
      "-\n",
      "Input sentence: Tom likes them.\n",
      "Decoded sentence: Tom est apaclés.\n",
      "\n",
      "-\n",
      "Input sentence: Tom likes them.\n",
      "Decoded sentence: Tom est apaclés.\n",
      "\n",
      "-\n",
      "Input sentence: Tom looks sick.\n",
      "Decoded sentence: Tom a teld.\n",
      "\n",
      "-\n",
      "Input sentence: Tom loves Mary.\n",
      "Decoded sentence: Tom a'travailléena.\n",
      "\n",
      "-\n",
      "Input sentence: Tom loves Mary.\n",
      "Decoded sentence: Tom a'travailléena.\n",
      "\n",
      "-\n",
      "Input sentence: Tom may change.\n",
      "Decoded sentence: Tom pout un peup de moir.\n",
      "\n",
      "-\n",
      "Input sentence: Tom needs help.\n",
      "Decoded sentence: Tom a besoén de toi.\n",
      "\n",
      "-\n",
      "Input sentence: Tom needs this.\n",
      "Decoded sentence: Tom a besonne est ici.\n",
      "\n",
      "-\n",
      "Input sentence: Tom needs work.\n",
      "Decoded sentence: Tom a bouriaité a torde.\n",
      "\n",
      "-\n",
      "Input sentence: Tom seems calm.\n",
      "Decoded sentence: Tom a soif mon.\n",
      "\n",
      "-\n",
      "Input sentence: Tom seems calm.\n",
      "Decoded sentence: Tom a soif mon.\n",
      "\n",
      "-\n",
      "Input sentence: Tom seems lost.\n",
      "Decoded sentence: Tom a bourté des boules.\n",
      "\n",
      "-\n",
      "Input sentence: Tom seems lost.\n",
      "Decoded sentence: Tom a bourté des boules.\n",
      "\n",
      "-\n",
      "Input sentence: Tom seems nice.\n",
      "Decoded sentence: Tom a biensé perde.\n",
      "\n",
      "-\n",
      "Input sentence: Tom seems nice.\n",
      "Decoded sentence: Tom a biensé perde.\n",
      "\n",
      "-\n",
      "Input sentence: Tom set a trap.\n",
      "Decoded sentence: Tom a feut un preib.\n",
      "\n",
      "-\n",
      "Input sentence: Tom stopped it.\n",
      "Decoded sentence: Tom a précha du temps.\n",
      "\n",
      "-\n",
      "Input sentence: Tom stopped it.\n",
      "Decoded sentence: Tom a précha du temps.\n",
      "\n",
      "-\n",
      "Input sentence: Tom stopped it.\n",
      "Decoded sentence: Tom a précha du temps.\n",
      "\n",
      "-\n",
      "Input sentence: Tom trusts him.\n",
      "Decoded sentence: Tom est ça.\n",
      "\n",
      "-\n",
      "Input sentence: Tom trusts you.\n",
      "Decoded sentence: Tom te hait.\n",
      "\n",
      "-\n",
      "Input sentence: Tom trusts you.\n",
      "Decoded sentence: Tom te hait.\n",
      "\n",
      "-\n",
      "Input sentence: Tom warned you.\n",
      "Decoded sentence: Tom avandoné mous es eu !\n",
      "\n",
      "-\n",
      "Input sentence: Tom was better.\n",
      "Decoded sentence: Tom était patisaut.\n",
      "\n",
      "-\n",
      "Input sentence: Tom was lonely.\n",
      "Decoded sentence: Tom a éné saot.\n",
      "\n",
      "-\n",
      "Input sentence: Tom won't know.\n",
      "Decoded sentence: Tom ne paut pas nager.\n",
      "\n",
      "-\n",
      "Input sentence: Tom won't know.\n",
      "Decoded sentence: Tom ne paut pas nager.\n",
      "\n",
      "-\n",
      "Input sentence: Tom won't mind.\n",
      "Decoded sentence: Tom ne ment pas chanter.\n",
      "\n",
      "-\n",
      "Input sentence: Tom's a doctor.\n",
      "Decoded sentence: Tom est édoiblème.\n",
      "\n",
      "-\n",
      "Input sentence: Tom's a doctor.\n",
      "Decoded sentence: Tom est édoiblème.\n",
      "\n",
      "-\n",
      "Input sentence: Tom's diabetic.\n",
      "Decoded sentence: Tom est attendé.\n",
      "\n",
      "-\n",
      "Input sentence: Tom's dreaming.\n",
      "Decoded sentence: Tom a peux y plui.\n",
      "\n",
      "-\n",
      "Input sentence: Tom's drowning.\n",
      "Decoded sentence: Tom se tagait.\n",
      "\n",
      "-\n",
      "Input sentence: Tom's drowning.\n",
      "Decoded sentence: Tom se tagait.\n",
      "\n",
      "-\n",
      "Input sentence: Tom's innocent.\n",
      "Decoded sentence: Tom est in égange.\n",
      "\n",
      "-\n",
      "Input sentence: Tom's not here.\n",
      "Decoded sentence: Tom ne feu  as coupard.\n",
      "\n",
      "-\n",
      "Input sentence: Tom's sweating.\n",
      "Decoded sentence: Tom est en train de tander.\n",
      "\n",
      "-\n",
      "Input sentence: Tom's upstairs.\n",
      "Decoded sentence: Tom est ens-mète.\n",
      "\n",
      "-\n",
      "Input sentence: Tom, don't die.\n",
      "Decoded sentence: Tom ne mante pas.\n",
      "\n",
      "-\n",
      "Input sentence: Treat her well.\n",
      "Decoded sentence: Sors pas la maison.\n",
      "\n",
      "-\n",
      "Input sentence: Treat her well.\n",
      "Decoded sentence: Sors pas la maison.\n",
      "\n",
      "-\n",
      "Input sentence: Treat him well.\n",
      "Decoded sentence: Fois contais !\n",
      "\n",
      "-\n",
      "Input sentence: Treat him well.\n",
      "Decoded sentence: Fois contais !\n",
      "\n",
      "-\n",
      "Input sentence: Try not to cry.\n",
      "Decoded sentence: Ne mot chez la porte !\n",
      "\n",
      "-\n",
      "Input sentence: Try not to cry.\n",
      "Decoded sentence: Ne mot chez la porte !\n",
      "\n",
      "-\n",
      "Input sentence: Try this sauce.\n",
      "Decoded sentence: Esse de encootrer.\n",
      "\n",
      "-\n",
      "Input sentence: Try to find it.\n",
      "Decoded sentence: Estaile de l'en aller.\n",
      "\n",
      "-\n",
      "Input sentence: Try to find it.\n",
      "Decoded sentence: Estaile de l'en aller.\n",
      "\n",
      "-\n",
      "Input sentence: Try to stop me.\n",
      "Decoded sentence: Dementez-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Try to stop me.\n",
      "Decoded sentence: Dementez-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Turn on the TV.\n",
      "Decoded sentence: Ne le suis pas imporde !\n",
      "\n",
      "-\n",
      "Input sentence: Turn on the TV.\n",
      "Decoded sentence: Ne le suis pas imporde !\n",
      "\n",
      "-\n",
      "Input sentence: Walk tall, son.\n",
      "Decoded sentence: Ragardez-vous à l'enterie!\n",
      "\n",
      "-\n",
      "Input sentence: Was that a yes?\n",
      "Decoded sentence: Qu'est-ce que c'est qu'icOOOn-trille tropffra ?\n",
      "\n",
      "-\n",
      "Input sentence: Wash your face.\n",
      "Decoded sentence: Détis est un ret le tois.\n",
      "\n",
      "-\n",
      "Input sentence: Wash your feet.\n",
      "Decoded sentence: Déteate ça.\n",
      "\n",
      "-\n",
      "Input sentence: Wash your feet.\n",
      "Decoded sentence: Déteate ça.\n",
      "\n",
      "-\n",
      "Input sentence: Watch the door.\n",
      "Decoded sentence: Rettre es lacmée.\n",
      "\n",
      "-\n",
      "Input sentence: Watch the door.\n",
      "Decoded sentence: Rettre es lacmée.\n",
      "\n",
      "-\n",
      "Input sentence: Watch the rear.\n",
      "Decoded sentence: Rette ton cariens.\n",
      "\n",
      "-\n",
      "Input sentence: Watch the road.\n",
      "Decoded sentence: Rette ton lat !\n",
      "\n",
      "-\n",
      "Input sentence: Watch the road.\n",
      "Decoded sentence: Rette ton lat !\n",
      "\n",
      "-\n",
      "Input sentence: Watch yourself.\n",
      "Decoded sentence: Regarde ditéruvée mon chante.\n",
      "\n",
      "-\n",
      "Input sentence: We all cheered.\n",
      "Decoded sentence: Nous sombes onsertensions.\n",
      "\n",
      "-\n",
      "Input sentence: We all cheered.\n",
      "Decoded sentence: Nous sombes onsertensions.\n",
      "\n",
      "-\n",
      "Input sentence: We all knew it.\n",
      "Decoded sentence: Nous l'aidorsonnes.\n",
      "\n",
      "-\n",
      "Input sentence: We all knew it.\n",
      "Decoded sentence: Nous l'aidorsonnes.\n",
      "\n",
      "-\n",
      "Input sentence: We all know it.\n",
      "Decoded sentence: Nous le somentis paraus.\n",
      "\n",
      "-\n",
      "Input sentence: We all know it.\n",
      "Decoded sentence: Nous le somentis paraus.\n",
      "\n",
      "-\n",
      "Input sentence: We all laughed.\n",
      "Decoded sentence: Nous avons tous pleuré.\n",
      "\n",
      "-\n",
      "Input sentence: We all laughed.\n",
      "Decoded sentence: Nous avons tous pleuré.\n",
      "\n",
      "-\n",
      "Input sentence: We all laughed.\n",
      "Decoded sentence: Nous avons tous pleuré.\n",
      "\n",
      "-\n",
      "Input sentence: We all laughed.\n",
      "Decoded sentence: Nous avons tous pleuré.\n",
      "\n",
      "-\n",
      "Input sentence: We almost left.\n",
      "Decoded sentence: Nous avraisons tropsée.\n",
      "\n",
      "-\n",
      "Input sentence: We are all set.\n",
      "Decoded sentence: Nous sommes montinte.\n",
      "\n",
      "-\n",
      "Input sentence: We are all set.\n",
      "Decoded sentence: Nous sommes montinte.\n",
      "\n",
      "-\n",
      "Input sentence: We are doctors.\n",
      "Decoded sentence: Nous sommes jesner sincrissés.\n",
      "\n",
      "-\n",
      "Input sentence: We can do that.\n",
      "Decoded sentence: Nous voulons des ess ycul.\n",
      "\n",
      "-\n",
      "Input sentence: We can proceed.\n",
      "Decoded sentence: Nous pouvons sousires.\n",
      "\n",
      "-\n",
      "Input sentence: We can't do it.\n",
      "Decoded sentence: Nous ne pouvons pas pourtir.\n",
      "\n",
      "-\n",
      "Input sentence: We can't do it.\n",
      "Decoded sentence: Nous ne pouvons pas pourtir.\n",
      "\n",
      "-\n",
      "Input sentence: We could crash.\n",
      "Decoded sentence: Nous pourrions lire.\n",
      "\n",
      "-\n",
      "Input sentence: We didn't kiss.\n",
      "Decoded sentence: Nous ne loussons ssemisinciner à narger.\n",
      "\n",
      "-\n",
      "Input sentence: We drank a lot.\n",
      "Decoded sentence: Nous feux un vourons.\n",
      "\n",
      "-\n",
      "Input sentence: We had a blast.\n",
      "Decoded sentence: Il sontuera teraiquire.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(8000,8100):\n",
    "    # Take one sequence (part of the training test)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
